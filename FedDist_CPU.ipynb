{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to run on googlecolab if did not install environment\n",
    "!pip install hickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPool1D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import hickle as hkl \n",
    "import copy\n",
    "from scipy.spatial import distance_matrix, distance\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which GPU to use\n",
    "# \"-1,0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "# DNN,CNN\n",
    "modelType = \"CNN\"\n",
    "\n",
    "# algorithm = \"FedDist\"\n",
    "algorithm = \"FedDist\"\n",
    "\n",
    "# UCI,REALWORLD_CLIENT\n",
    "dataSetName = 'REALWORLD_CLIENT'\n",
    "\n",
    "#BALANCED, UNBALANCED\n",
    "dataConfig = \"BALANCED\"\n",
    "\n",
    "#ADAM, SGD\n",
    "optimizer = \"SGD\"\n",
    "\n",
    "# Have model evaluate on the Global testset\n",
    "ClientAllTest = True\n",
    "\n",
    "# Neuron distance measurement \n",
    "euclid = True\n",
    "\n",
    "# Asynchronous client test\n",
    "asyncTest = False\n",
    "\n",
    "# if 0, uses 33% as starting pool\n",
    "startingTrainPool = 0\n",
    "\n",
    "clientDeleteCount = 3\n",
    "clientAddCount = 5\n",
    "\n",
    "# only needed to set if clientAddCount = clientDeleteCount, otherwise it follows a small algorithm to calculate automatically\n",
    "asyncInterval = 5\n",
    "\n",
    "# Generate results in seperate graph\n",
    "seperateGraph = False\n",
    "\n",
    "# Save the client models a .h5 file\n",
    "savedClientModel = 0\n",
    "\n",
    "# Show training verbose: 0,1\n",
    "showTrainVerbose = 0\n",
    "\n",
    "# input window size \n",
    "segment_size = 128\n",
    "\n",
    "# input channel count\n",
    "num_input_channels = 6\n",
    "\n",
    "# client learning rate\n",
    "learningRate = 0.01\n",
    "\n",
    "# model drop out rate\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# local epoch\n",
    "localEpoch = 5\n",
    "\n",
    "# communication round\n",
    "communicationRound = 200\n",
    "\n",
    "\n",
    "# Seed for data partioning and TF training\n",
    "randomSeed = 1\n",
    "\n",
    "# FedDist threshold\n",
    "stdCount = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying activities and where the results will be stored \n",
    "if(dataSetName == 'UCI'):\n",
    "    ACTIVITY_LABEL = ['WALKING', 'WALKING_UPSTAIRS','WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "else:\n",
    "    ACTIVITY_LABEL = ['climbingdown', 'climbingup', 'jumping','lying', 'running', 'sitting', 'standing', 'walking']\n",
    "activityCount = len(ACTIVITY_LABEL)\n",
    "\n",
    "architectureType = str(algorithm)+'_'+'LR_'+str(localEpoch)+'LE_'+str(communicationRound)+'CR_'+str(modelType)\n",
    "mainDir = ''\n",
    "filepath = mainDir + 'savedModels/'+architectureType+'/'+dataSetName+'/'\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "if(dataSetName=='UCI'):\n",
    "    clientCount = 5\n",
    "else:\n",
    "    clientCount = 15\n",
    "np.random.seed(randomSeed)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.random.set_seed(randomSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing data variables\n",
    "\n",
    "clientDataTrain = []\n",
    "clientLabelTrain = []\n",
    "clientDataTest = []\n",
    "clientLabelTest = []\n",
    "\n",
    "centralTrainData = []\n",
    "centralTrainLabel = []\n",
    "\n",
    "centralTestData = []\n",
    "centralTestLabel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "if(dataSetName == \"UCI\"):\n",
    "\n",
    "    def load_file(filepath):\n",
    "        dataframe = pd.read_csv(filepath, header=None)\n",
    "        return dataframe.values\n",
    "\n",
    "\n",
    "    def load_group(filenames, prefix=''):\n",
    "        loaded = list()\n",
    "        for name in filenames:\n",
    "            data = load_file(prefix + name)\n",
    "            loaded.append(data)\n",
    "        loaded = np.dstack(loaded)\n",
    "        return loaded\n",
    "\n",
    "\n",
    "    def load_dataset(group, prefix=''):\n",
    "        filepath = mainDir + 'datasetStandardized/'+prefix + '/' + group + '/'\n",
    "        filenames = list()\n",
    "        filenames += ['AccX'+prefix+'.csv', 'AccY' +\n",
    "                      prefix+'.csv', 'AccZ'+prefix+'.csv']\n",
    "        filenames += ['GyroX'+prefix+'.csv', 'GyroY' +\n",
    "                      prefix+'.csv', 'GyroZ'+prefix+'.csv']\n",
    "        X = load_group(filenames, filepath)\n",
    "        y = load_file(mainDir + 'datasetStandardized/'+prefix +\n",
    "                      '/' + group + '/Label'+prefix+'.csv')\n",
    "        return X, y\n",
    "    trainData, trainLabel = load_dataset('train', dataSetName)\n",
    "    evalData, evalLabel = load_dataset('eval', dataSetName)\n",
    "    allData = np.float32(np.vstack((trainData, evalData)))\n",
    "    allLabel = np.vstack((trainLabel, evalLabel))\n",
    "\n",
    "    # split data into 80 - 20 \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle = True)\n",
    "    skf.get_n_splits(allData, allLabel)\n",
    "    partitionedData = list()\n",
    "    partitionedLabel = list()\n",
    "    for train_index, test_index in skf.split(allData, allLabel):\n",
    "        partitionedData.append(allData[test_index])\n",
    "        partitionedLabel.append(allLabel[test_index])\n",
    "\n",
    "    centralTrainData = np.vstack((partitionedData[:4]))\n",
    "    centralTrainLabel = np.vstack((partitionedLabel[:4]))\n",
    "    centralTestData = partitionedData[4]\n",
    "    centralTestLabel = partitionedLabel[4]\n",
    "\n",
    "    trainData = list()\n",
    "    trainLabel = list()\n",
    "    testData = list()\n",
    "    testLabel = list()\n",
    "\n",
    "    if(dataConfig == \"BALANCED\"):\n",
    "        skf = StratifiedKFold(n_splits=clientCount,shuffle = True , random_state = randomSeed)\n",
    "        skf.get_n_splits(centralTrainData, centralTrainLabel)\n",
    "        for train_index, test_index in skf.split(centralTrainData, centralTrainLabel):\n",
    "            trainData.append(centralTrainData[test_index])\n",
    "            trainLabel.append(centralTrainLabel[test_index].ravel())\n",
    "    else:\n",
    "    # unbalanced\n",
    "        kf = KFold(n_splits=clientCount, shuffle=True,random_state = randomSeed)\n",
    "        kf.get_n_splits(centralTrainData)\n",
    "        for train_index, test_index in kf.split(centralTrainData):\n",
    "            trainData.append(centralTrainData[test_index])\n",
    "            trainLabel.append(centralTrainLabel[test_index].ravel())\n",
    "\n",
    "    #slittestSetInto5\n",
    "    skf.get_n_splits(centralTestData, centralTestLabel)\n",
    "    for train_index, test_index in skf.split(centralTestData, centralTestLabel):\n",
    "        testData.append(centralTestData[test_index])\n",
    "        testLabel.append(centralTestLabel[test_index].ravel())\n",
    "\n",
    "    clientDataTrain = trainData\n",
    "    clientLabelTrain = trainLabel\n",
    "    clientDataTest = testData\n",
    "    clientLabelTest = testLabel\n",
    "    \n",
    "    centralTrainData = (np.vstack((clientDataTrain)))\n",
    "    centralTrainLabel = (np.hstack((clientLabelTrain)))\n",
    "\n",
    "    centralTestData = (np.vstack((clientDataTest)))\n",
    "    centralTestLabel = (np.hstack((clientLabelTest)))\n",
    "else:\n",
    "    clientData = []\n",
    "    clientLabel = []\n",
    "\n",
    "    dataSetName = 'REALWORLD_CLIENT'\n",
    "    for i in range(0,15):\n",
    "        accX = hkl.load('datasetStandardized/'+dataSetName+'/'+str(i)+'/AccX'+dataSetName+'.hkl')\n",
    "        accY = hkl.load('datasetStandardized/'+dataSetName+'/'+str(i)+'/AccY'+dataSetName+'.hkl')\n",
    "        accZ = hkl.load('datasetStandardized/'+dataSetName+'/'+str(i)+'/AccZ'+dataSetName+'.hkl')\n",
    "        gyroX = hkl.load('datasetStandardized/'+dataSetName+'/'+str(i)+'/GyroX'+dataSetName+'.hkl')\n",
    "        gyroY = hkl.load('datasetStandardized/'+dataSetName+'/'+str(i)+'/GyroY'+dataSetName+'.hkl')\n",
    "        gyroZ = hkl.load('datasetStandardized/'+dataSetName+'/'+str(i)+'/GyroZ'+dataSetName+'.hkl')\n",
    "        label = hkl.load('datasetStandardized/'+dataSetName+'/'+str(i)+'/Label'+dataSetName+'.hkl')\n",
    "        clientData.append(np.dstack((accX,accY,accZ,gyroX,gyroY,gyroZ)))\n",
    "        clientLabel.append(label)\n",
    "    \n",
    "    if(dataConfig == \"BALANCED\"):\n",
    "        for i in range (0,15):\n",
    "            skf = StratifiedKFold(n_splits=5, shuffle=True,random_state = randomSeed)\n",
    "            skf.get_n_splits(clientData[i], clientLabel[i])\n",
    "            partitionedData = list()\n",
    "            partitionedLabel = list()    \n",
    "            for train_index, test_index in skf.split(clientData[i], clientLabel[i]):\n",
    "                partitionedData.append(clientData[i][test_index])\n",
    "                partitionedLabel.append(clientLabel[i][test_index])\n",
    "            clientDataTrain.append((np.vstack((partitionedData[:4]))))\n",
    "            clientLabelTrain.append((np.hstack((partitionedLabel[:4]))))\n",
    "            clientDataTest.append((partitionedData[4]))\n",
    "            clientLabelTest.append((partitionedLabel[4]))\n",
    "    else:\n",
    "        for i in range (0,15):\n",
    "            kf = KFold(n_splits=5, shuffle=True,random_state = randomSeed)\n",
    "            kf.get_n_splits(clientData[i])\n",
    "            partitionedData = list()\n",
    "            partitionedLabel = list()    \n",
    "            for train_index, test_index in kf.split(clientData[i]):\n",
    "                partitionedData.append(clientData[i][test_index])\n",
    "                partitionedLabel.append(clientLabel[i][test_index])\n",
    "            clientDataTrain.append((np.vstack((partitionedData[:4]))))\n",
    "            clientLabelTrain.append((np.hstack((partitionedLabel[:4]))))\n",
    "            clientDataTest.append((partitionedData[4]))\n",
    "            clientLabelTest.append((partitionedLabel[4]))\n",
    "    centralTrainData = (np.vstack((clientDataTrain)))\n",
    "    centralTrainLabel = (np.hstack((clientLabelTrain)))\n",
    "\n",
    "    centralTestData = (np.vstack((clientDataTest)))\n",
    "    centralTestLabel = (np.hstack((clientLabelTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing CNN model\n",
    "if(modelType == \"CNN\"):\n",
    "    def create_keras_model():\n",
    "        return Sequential([\n",
    "            Conv1D(196,  16, input_shape=(segment_size,num_input_channels), activation='relu', padding='same',name = 'base1'),\n",
    "            MaxPool1D(pool_size=4, padding='same',name = 'base2'),\n",
    "            Flatten(name = 'flatten'),\n",
    "            Dense(units=1024, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(activityCount, activation='softmax')\n",
    "    ])\n",
    "    serverModel = Sequential()\n",
    "    serverModel.add(Conv1D(196,  16, activation='relu',name = 'base1',input_shape=(segment_size,num_input_channels), padding='same'))\n",
    "    serverModel.add(MaxPool1D(pool_size=4, padding='same',name = 'base2'))\n",
    "    serverModel.add(Flatten(name = 'flatten'))\n",
    "    serverModel.add(Dense(1024, activation = 'relu'))\n",
    "    serverModel.add(Dropout(dropout_rate))\n",
    "    serverModel.add(Dense(activityCount, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing DNN model\n",
    "if(modelType == \"DNN\"):\n",
    "    def create_keras_model():\n",
    "        return Sequential([\n",
    "            Flatten(input_shape=(segment_size,num_input_channels), name = 'flatten'),\n",
    "            Dense(units=400, activation='relu',name = 'base'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(units=100, activation='relu',name = 'personalized'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(activityCount, activation='softmax', name ='clientSoft')\n",
    "        ])\n",
    "        # initialize server\n",
    "    serverModel = Sequential()\n",
    "    serverModel.add(Flatten(input_shape=(segment_size,num_input_channels), name = 'flatten' ))\n",
    "    serverModel.add(Dense(400, activation = 'relu', name='base'))\n",
    "    serverModel.add(Dropout(dropout_rate))\n",
    "    serverModel.add(Dense(100, activation = 'relu',name='serverP'))\n",
    "    serverModel.add(Dropout(dropout_rate))\n",
    "    serverModel.add(Dense(activityCount, activation='softmax',name='serverSoft'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create new custom CNN\n",
    "def createCNN(filter_count = 192 ,dense_unit = 1024):\n",
    "    cnnModel = Sequential()\n",
    "    cnnModel.add(Conv1D(filter_count,  16, activation='relu',name = 'base1',input_shape=(segment_size,num_input_channels), padding='same'))\n",
    "    cnnModel.add(MaxPool1D(pool_size=4, padding='same',name = 'base2'))\n",
    "    cnnModel.add(Flatten(name = 'flatten'))\n",
    "    cnnModel.add(Dense(dense_unit, activation = 'relu'))\n",
    "    cnnModel.add(Dropout(dropout_rate))\n",
    "    cnnModel.add(Dense(activityCount, activation='softmax'))\n",
    "    return cnnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the server model\n",
    "if(optimizer == \"SGD\"):\n",
    "    serverModel.compile(optimizer=SGD(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "else:\n",
    "    serverModel.compile(optimizer=Adam(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "\n",
    "serverModel.save_weights(filepath+'serverWeights.h5')\n",
    "weights = serverModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing client model\n",
    "local_nets = {}\n",
    "local_histories = {}\n",
    "\n",
    "for i in range(0,clientCount):\n",
    "    local_nets[i] = create_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of metrics during training\n",
    "# client models test againts own test-set\n",
    "trainLossHistory = []\n",
    "trainAccHistory = []\n",
    "testLossHistory = []\n",
    "testAccHistory = []\n",
    "\n",
    "stdTrainLossHistory = []\n",
    "stdTrainAccHistory = []\n",
    "stdTestLossHistory = []\n",
    "stdTestAccHistory = []\n",
    "\n",
    "# client models test againts all test-set\n",
    "\n",
    "clientTrainLossHistory = []\n",
    "clientTrainAccHistory = []\n",
    "clientTestLossHistory = []\n",
    "clientTestAccHistory = []\n",
    "\n",
    "clientStdTrainLossHistory = []\n",
    "clientStdTrainAccHistory = []\n",
    "clientStdTestLossHistory = []\n",
    "clientStdTestAccHistory = []\n",
    "\n",
    "\n",
    "# server test againts all test-set\n",
    "\n",
    "serverTrainLossHistory = []\n",
    "serverTrainAccHistory = []\n",
    "serverTestLossHistory = []\n",
    "serverTestAccHistory = []\n",
    "\n",
    "meanHistoryDist = []\n",
    "stdHistoryDist = []\n",
    "\n",
    "meanRoundLayerHistory = []\n",
    "stdRoundLayerHistory = []\n",
    "\n",
    "meanRoundGeneralLayerHistory = []\n",
    "stdRoundGeneralLayerHistory = []\n",
    "\n",
    "bestModelRound = 0\n",
    "currentAccuracy = 0.0\n",
    "serverCurrentAccuracy = 0.0\n",
    "serverbestModelRound = 0\n",
    "bestServerModel = None\n",
    "bestServerModelWeights = None\n",
    "best_local_nets = {}\n",
    "best_local_weights = {}\n",
    "\n",
    "stage = 1\n",
    "clientParticipant = clientCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates an array to represent model type per layer\n",
    "layerType = []\n",
    "for idx in range(len(serverModel.layers)):\n",
    "    temp = serverModel.get_layer(index = idx).__class__.__name__\n",
    "    if(\"Conv\" in temp):\n",
    "        layerType.append(0)\n",
    "    elif(\"Dense\" in temp):\n",
    "        layerType.append(1)\n",
    "        \n",
    "        \n",
    "layerMap = {}\n",
    "counter = 0\n",
    "for index,name in enumerate(serverModel.layers):\n",
    "    if(\"Conv\" in str(name) or \"Dense\" in str(name)):\n",
    "        layerMap[counter] = index\n",
    "        counter += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mantalTest(serverModel,local_nets):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating dataset size weight per client\n",
    "local_coeffs = {}\n",
    "for i in range(0,clientCount):\n",
    "    local_coeffs[i] = np.float32(len(clientLabelTrain[i])) / np.float32(len(centralTrainLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating activities weight for weighted training per client\n",
    "local_class_weights = {}\n",
    "for i in range(0,clientCount):\n",
    "    local_class_weights[i] = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(clientLabelTrain[i]),\n",
    "                                                     clientLabelTrain[i].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping model weights for 2d matrix multiplications\n",
    "def computeWeights(modelWeight):\n",
    "    modelWeight = np.asarray(modelWeight)\n",
    "    modelWeightsPrep = []\n",
    "    for i in range(int(modelWeight.shape[0]/ 2)):\n",
    "    #   conv\n",
    "        if(layerType[i] == 0):\n",
    "            kernelSize = modelWeight[i*2].shape[0]\n",
    "            inputChannel = modelWeight[i*2].shape[1]\n",
    "            outputChannel = modelWeight[i*2].shape[2]\n",
    "            weightReshaped = modelWeight[i*2].reshape(kernelSize*inputChannel,outputChannel).T\n",
    "            biasReshaped = modelWeight[i*2+1].reshape(-1,1)\n",
    "            modelWeightsPrep.append(np.hstack((weightReshaped,biasReshaped)))\n",
    "    #    dense\n",
    "        if(layerType[i] == 1):\n",
    "            weightReshaped = modelWeight[i*2].T\n",
    "            biasReshaped = modelWeight[i*2+1].reshape(-1,1)\n",
    "            modelWeightsPrep.append(np.hstack((weightReshaped,biasReshaped)))\n",
    "    modelWeightsPrep = np.asarray(modelWeightsPrep)\n",
    "    return modelWeightsPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization for asynchronous client training, client selection\n",
    "roundEnd = []\n",
    "if(asyncTest):\n",
    "    trainPool = []\n",
    "    idlePool = []\n",
    "    \n",
    "    if(startingTrainPool == 0):\n",
    "        initialClientCount = int(clientCount *0.34) \n",
    "        if(initialClientCount == 1):\n",
    "            initialClientCount = 2\n",
    "    else:\n",
    "        initialClientCount = startingTrainPool\n",
    "       \n",
    "    trainPool = list(range(initialClientCount))\n",
    "    idlePool = list(range(initialClientCount,clientCount))\n",
    "    \n",
    "    if(clientDeleteCount != clientAddCount):\n",
    "        stages = math.ceil((clientCount  - len(trainPool)) / (clientAddCount - clientDeleteCount))\n",
    "        intervals = int(communicationRound / (stages * 2))\n",
    "    else:\n",
    "        intervals = asyncInterval\n",
    "        stages = int(communicationRound / intervals)\n",
    "    for clientChangeRound in range(1,stages+1):\n",
    "        roundEnd.append(intervals * clientChangeRound) \n",
    "else:\n",
    "    trainPool = range(clientCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of client distance (for distance measurement)\n",
    "clientEuclidDistMean = {}\n",
    "clientEuclidDistStd = {}\n",
    "for i in range(clientCount):\n",
    "    clientEuclidDistMean[i] = np.zeros(communicationRound)\n",
    "    clientEuclidDistStd[i] = np.zeros(communicationRound)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Federated learning training\n",
    "for roundNum in range(0,communicationRound):\n",
    "    start_time = time.time()\n",
    "    trainAcc = []\n",
    "    trainLoss = []\n",
    "    \n",
    "    testAcc = []\n",
    "    testLoss = []\n",
    "    \n",
    "    clientTrainAcc = []\n",
    "    clientTrainLoss = []\n",
    "\n",
    "    clientTestAcc = []\n",
    "    clientTestLoss = []\n",
    "    \n",
    "    local_weights = {}\n",
    "    \n",
    "    if(asyncTest):\n",
    "        if(roundNum in roundEnd):\n",
    "            for i in range(clientDeleteCount):\n",
    "                if(len(trainPool) != 0):\n",
    "                    selection = random.choice(list(enumerate(trainPool)))\n",
    "                    del trainPool[selection[0]]\n",
    "                    idlePool.append(selection[1])\n",
    "            for i in range(clientAddCount):\n",
    "                if(len(idlePool) != 0):\n",
    "                    selection = random.choice(list(enumerate(idlePool)))\n",
    "                    del idlePool[selection[0]]\n",
    "                    trainPool.append(selection[1])\n",
    "\n",
    "        participantDataInstance = []\n",
    "        for index,i in enumerate(trainPool):\n",
    "            participantDataInstance.append(clientLabelTrain[i])       \n",
    "        participantDataInstance = (np.hstack((participantDataInstance)))\n",
    "        local_coeffs = {}\n",
    "        for index, i in enumerate(trainPool):\n",
    "            local_coeffs[i] = np.float32(len(clientLabelTrain[i])) / np.float32(len(participantDataInstance))\n",
    "    for index,i in enumerate(trainPool):\n",
    "        print(\"Status: Round #\"+ str(roundNum)+ \" Client #\"+ str(i))\n",
    "\n",
    "        if(algorithm==\"FEDPER\"):\n",
    "            local_nets[i].load_weights(filepath+'serverWeights.h5',by_name=True)\n",
    "        else:\n",
    "            local_nets[i].load_weights(filepath+'serverWeights.h5',by_name=False)\n",
    "        if(optimizer == \"SGD\"):\n",
    "            local_nets[i].compile(optimizer=SGD(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "        else:\n",
    "            local_nets[i].compile(optimizer=Adam(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "        local_histories[i] = local_nets[i].fit(clientDataTrain[i], clientLabelTrain[i], class_weight=local_class_weights[i], epochs = localEpoch,verbose=showTrainVerbose)\n",
    "\n",
    "\n",
    "        local_weights[i] = local_nets[i].get_weights()\n",
    "        trainAcc.append(local_histories[i].history['acc'])\n",
    "        trainLoss.append(local_histories[i].history['loss'])\n",
    "        \n",
    "#         testing againts their own testset\n",
    "        testModelMetrics = local_nets[i].evaluate(clientDataTest[i], clientLabelTest[i],verbose = showTrainVerbose)\n",
    "        testAcc.append(testModelMetrics[1])\n",
    "        testLoss.append(testModelMetrics[0])\n",
    "        \n",
    "        \n",
    "        if(ClientAllTest == True):\n",
    "#           testing againts their all testset\n",
    "            clientTrainModelMetrics = local_nets[i].evaluate(centralTrainData, centralTrainLabel, verbose=showTrainVerbose)\n",
    "            clientTrainAcc.append(clientTrainModelMetrics[1])\n",
    "            clientTrainLoss.append(clientTrainModelMetrics[0])\n",
    "\n",
    "            clientTestModelMetrics = local_nets[i].evaluate(centralTestData, centralTestLabel,verbose = showTrainVerbose)\n",
    "            clientTestAcc.append(clientTestModelMetrics[1])\n",
    "            clientTestLoss.append(clientTestModelMetrics[0])\n",
    "    \n",
    "        for j in range(0,len(local_weights[i])):\n",
    "            local_weights[i][j] = local_weights[i][j] * local_coeffs[i]\n",
    "        \n",
    "    if(euclid):\n",
    "        meanServerClient = []\n",
    "        stdServerClient = []\n",
    "        serverShape = np.asarray(computeWeights(serverModel.get_weights()))\n",
    "        localMeanClientLayer = []\n",
    "        localStdClientLayer = []\n",
    "        for index, clientIndex in enumerate(trainPool):\n",
    "            localMeanServerClient = []\n",
    "            localStdServerClient = []\n",
    "\n",
    "            localShape = np.asarray(computeWeights(local_nets[clientIndex].get_weights()))\n",
    "            if(algorithm != 'FEDPER'):\n",
    "                for i in range(serverShape.shape[0]):\n",
    "                    newLayerDist = np.sqrt((serverShape[i] - localShape[i])**2)\n",
    "                    localMeanServerClient.append(np.mean(newLayerDist))\n",
    "                    localStdServerClient.append(np.std(newLayerDist))\n",
    "            else:\n",
    "                newLayerDist = np.sqrt((serverShape[0] - localShape[0])**2)\n",
    "                localMeanServerClient.append(np.mean(newLayerDist))\n",
    "                localStdServerClient.append(np.std(newLayerDist))\n",
    "                \n",
    "            localMeanClientLayer.append(localMeanServerClient)\n",
    "            localStdClientLayer.append(localStdServerClient)\n",
    "            meanServerClient.append(np.mean(localMeanServerClient))\n",
    "            stdServerClient.append(np.mean(localStdServerClient))\n",
    "            clientEuclidDistMean[clientIndex][roundNum] = np.mean(localMeanServerClient)\n",
    "            clientEuclidDistStd[clientIndex][roundNum] = np.mean(localStdServerClient)\n",
    "            \n",
    "#         15 clients \n",
    "        meanHistoryDist.append(np.asarray(meanServerClient))\n",
    "        stdHistoryDist.append(np.asarray(stdServerClient))\n",
    "\n",
    "#         per layer distance\n",
    "        meanRoundLayerHistory.append(np.mean(localMeanClientLayer,axis = 0))\n",
    "        stdRoundLayerHistory.append(np.mean(localStdClientLayer,axis=0))\n",
    "        \n",
    "#         all layer distance\n",
    "        meanRoundGeneralLayerHistory.append(np.mean(localMeanClientLayer))\n",
    "        stdRoundGeneralLayerHistory.append(np.mean(localStdClientLayer))\n",
    "        \n",
    "\n",
    "    trainAccHistory.append(np.mean(trainAcc))\n",
    "    stdTrainAccHistory.append(np.std(trainAcc))\n",
    "    trainLossHistory.append(np.mean(trainLoss))\n",
    "    stdTrainLossHistory.append(np.std(trainLoss))\n",
    "\n",
    "    \n",
    "    meanTestAcc = np.mean(testAcc)\n",
    "    \n",
    "    testAccHistory.append(meanTestAcc)\n",
    "    stdTestAccHistory.append(np.std(testAcc))\n",
    "    testLossHistory.append(np.mean(testLoss))\n",
    "    stdTestLossHistory.append(np.std(testLoss))\n",
    "    \n",
    "    \n",
    "    if(meanTestAcc > currentAccuracy):\n",
    "        for index,net in enumerate(local_nets):\n",
    "            best_local_nets[index] = copy.copy(local_nets[index])\n",
    "        currentAccuracy = meanTestAcc\n",
    "        bestModelRound = roundNum + 1\n",
    "    \n",
    "    \n",
    "    if(ClientAllTest == True):\n",
    "        clientTrainLossHistory.append(np.mean(clientTrainLoss))\n",
    "        clientTrainAccHistory.append(np.mean(clientTrainAcc))\n",
    "        clientTestLossHistory.append(np.mean(clientTestLoss))\n",
    "        clientTestAccHistory.append(np.mean(clientTestAcc))\n",
    "\n",
    "        clientStdTrainLossHistory.append(np.std(clientTrainLoss))\n",
    "        clientStdTrainAccHistory.append(np.std(clientTrainAcc))\n",
    "        clientStdTestLossHistory.append(np.std(clientTestLoss))\n",
    "        clientStdTestAccHistory.append(np.std(clientTestAcc))\n",
    "\n",
    "    # return weights to server and sum all the model weights \n",
    "    \n",
    "    \n",
    "    weights = []\n",
    "    for i in local_weights:\n",
    "        weights.append(local_weights[i])\n",
    "    new_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        new_weights.append(np.asarray(\n",
    "            [np.array(weights_).sum(axis=0)\\\n",
    "                for weights_ in zip(*weights_list_tuple)]))\n",
    "    serverModel.set_weights(np.asarray(new_weights))\n",
    "    \n",
    "#    FedDist main implemenation begins here\n",
    "\n",
    "    for layer in range(len(layerType) - 1):\n",
    "        if(layer != len(layerType) - 1):\n",
    "            distanceMatrix = []\n",
    "            allClientWeight = {}\n",
    "            serverWeights = computeWeights(serverModel.get_weights())\n",
    "\n",
    "\n",
    "            for i,clientIndex in enumerate(trainPool):\n",
    "                clientWeights = computeWeights(local_nets[clientIndex].get_weights())\n",
    "                allClientWeight[clientIndex] = clientWeights\n",
    "                clientDistance = []\n",
    "                for k in range(serverWeights[layer].shape[0]):\n",
    "                    clientDistance.append(distance.euclidean(clientWeights[layer][k],serverWeights[layer][k]))\n",
    "                distanceMatrix.append(clientDistance)\n",
    "\n",
    "            distanceMatrix = np.asarray(distanceMatrix)\n",
    "            means = np.mean(distanceMatrix,axis = 0)\n",
    "            stds = np.std(distanceMatrix,axis = 0)\n",
    "            stdThreshold = stdCount + np.floor(roundNum / 5) * 0.25 \n",
    "            threshHold = means + (stdThreshold * stds)\n",
    "\n",
    "            nextLayerOutWeights = (allClientWeight[0][layer+1].shape[1] - 1) / allClientWeight[0][layer].shape[0]\n",
    "            newUnit = []\n",
    "            outerUnit = []\n",
    "            for i,clientIndex in enumerate(trainPool):\n",
    "                for k in range(serverWeights[layer].shape[0]):\n",
    "                    if(distanceMatrix[clientIndex][k] > threshHold[k]):\n",
    "                        newUnit.append(allClientWeight[clientIndex][layer][k])\n",
    "                        nextLayerIndexStart = int(nextLayerOutWeights * k)\n",
    "                        nextLayerIndexEnd = int(nextLayerIndexStart+nextLayerOutWeights)        \n",
    "                        outerUnit.append(allClientWeight[clientIndex][layer+1][:,nextLayerIndexStart:nextLayerIndexEnd])\n",
    "            if(len(newUnit) == 0):\n",
    "                print(\"No new unit\")\n",
    "                continue\n",
    "            else:\n",
    "                print(\"New units added :\"+str(len(newUnit)) + \" on layer : \"+str(layer) )\n",
    "            serverWeights[layer] = np.vstack((serverWeights[layer],newUnit))\n",
    "\n",
    "            outwardsUnit = np.hstack(outerUnit)\n",
    "            bias = serverWeights[layer+1][:,serverWeights[layer+1].shape[1]-1:]\n",
    "            outwardsUnit = np.hstack((serverWeights[layer+1][:,:serverWeights[layer+1].shape[1]-1],outwardsUnit))\n",
    "            outwardsUnit = np.hstack((outwardsUnit,bias))\n",
    "            serverWeights[layer+1] = outwardsUnit\n",
    "            newWeights = []\n",
    "            for layerIndex in range(len(serverWeights)):\n",
    "                sizeWithoutBias = serverWeights[layerIndex].shape[1] -1\n",
    "                if(layerType[layerIndex] == 0):\n",
    "                    layerWeight = serverWeights[layerIndex][:,:sizeWithoutBias].T.reshape(16,6,-1)\n",
    "                else:\n",
    "                    layerWeight = serverWeights[layerIndex][:,:sizeWithoutBias].T\n",
    "                layerBias = serverWeights[layerIndex][:,sizeWithoutBias:].ravel()\n",
    "                newWeights.append(layerWeight)\n",
    "                newWeights.append(layerBias)\n",
    "    \n",
    "            del serverModel \n",
    "            serverModel = createCNN(filter_count = newWeights[0].shape[2],dense_unit = newWeights[2].shape[1])\n",
    "            serverModel.set_weights(newWeights)\n",
    "\n",
    "            for i in range(layer+1):\n",
    "                serverModel.layers[layerMap[i]].trainable = False\n",
    "            local_nets = {}\n",
    "            local_weights = {}\n",
    "\n",
    "            for i,index in enumerate(trainPool):\n",
    "                local_nets[index] = createCNN(filter_count = newWeights[0].shape[2],dense_unit = newWeights[2].shape[1])\n",
    "                local_nets[index].set_weights(newWeights)\n",
    "                for i in range(layer+1):\n",
    "                    local_nets[index].layers[layerMap[i]].trainable = False\n",
    "                if(optimizer == \"SGD\"):\n",
    "                    local_nets[index].compile(optimizer=SGD(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "                else:\n",
    "                    local_nets[index].compile(optimizer=Adam(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "                local_nets[index].fit(clientDataTrain[index], clientLabelTrain[index], class_weight=local_class_weights[index], epochs = localEpoch,verbose=showTrainVerbose)\n",
    "                \n",
    "                local_weights[index] = local_nets[index].get_weights()\n",
    "                \n",
    "                for j in range(0,len(local_weights[index])):\n",
    "                    local_weights[index][j] = local_weights[index][j] * local_coeffs[index]\n",
    "\n",
    "            weights = []\n",
    "            for i in local_weights:\n",
    "                weights.append(local_weights[i])\n",
    "            new_weights = list()\n",
    "            for weights_list_tuple in zip(*weights):\n",
    "                new_weights.append(np.asarray(\n",
    "                    [np.array(weights_).sum(axis=0)\\\n",
    "                        for weights_ in zip(*weights_list_tuple)]))\n",
    "            serverModel.set_weights(np.asarray(new_weights))\n",
    "\n",
    "\n",
    "            for i in range(layer+1):\n",
    "                serverModel.layers[layerMap[i]].trainable = True\n",
    "                for index,clientId in enumerate(trainPool):\n",
    "                    local_nets[clientId].layers[layerMap[i]].trainable = True\n",
    "\n",
    "    serverModel.summary()\n",
    "    \n",
    "#     Main FedDist implementations end here====================\n",
    "    serverModel.save_weights(filepath+'serverWeights.h5')\n",
    "    if(algorithm != 'FEDPER'):\n",
    "        if(optimizer == \"SGD\"):\n",
    "            serverModel.compile(optimizer=SGD(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "        else:\n",
    "            serverModel.compile(optimizer=Adam(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "        serverTrainMetrics = serverModel.evaluate(centralTrainData, centralTrainLabel,verbose = showTrainVerbose)\n",
    "        serverTrainLossHistory.append(serverTrainMetrics[0])\n",
    "        serverTrainAccHistory.append(serverTrainMetrics[1])\n",
    "        serverTestMetrics = serverModel.evaluate(centralTestData, centralTestLabel,verbose = showTrainVerbose)\n",
    "        serverTestLossHistory.append(serverTestMetrics[0])\n",
    "        serverTestAccHistory.append(serverTestMetrics[1])\n",
    "        if(serverTestMetrics[1]>serverCurrentAccuracy):\n",
    "            serverCurrentAccuracy = serverTestMetrics[1]\n",
    "            serverbestModelRound = roundNum + 1\n",
    "            bestServerModel = copy.copy(serverModel)\n",
    "endTime = time.time() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting round end for the asyncronous test \n",
    "for index in range(len(roundEnd)):\n",
    "    roundEnd[index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes to a np formats\n",
    "# std of all clients\n",
    "stdTrainLossHistory = np.asarray(stdTrainLossHistory)\n",
    "stdTrainAccHistory = np.asarray(stdTrainAccHistory)\n",
    "stdTestLossHistory = np.asarray(stdTestLossHistory)\n",
    "stdTestAccHistory = np.asarray(stdTestAccHistory)\n",
    "\n",
    "\n",
    "clientStdTrainLossHistory = np.asarray(clientStdTrainLossHistory)\n",
    "clientStdTrainAccHistory = np.asarray(clientStdTrainAccHistory)\n",
    "clientStdTestLossHistory = np.asarray(clientStdTestLossHistory)\n",
    "clientStdTestAccHistory = np.asarray(clientStdTestAccHistory)\n",
    "\n",
    "if(euclid):\n",
    "    meanHistoryDist = np.asarray(meanHistoryDist).T\n",
    "    stdHistoryDist = np.asarray(stdHistoryDist).T\n",
    "    meanRoundLayerHistory = np.asarray(meanRoundLayerHistory).T\n",
    "    stdRoundLayerHistory = np.asarray(stdRoundLayerHistory).T\n",
    "    meanRoundGeneralLayerHistory = np.asarray(meanRoundGeneralLayerHistory)\n",
    "    stdRoundGeneralLayerHistory = np.asarray(stdRoundGeneralLayerHistory)\n",
    "# mean\n",
    "trainLossHistory = np.asarray(trainLossHistory)\n",
    "trainAccHistory = np.asarray(trainAccHistory)\n",
    "testLossHistory = np.asarray(testLossHistory)\n",
    "testAccHistory = np.asarray(testAccHistory)\n",
    "\n",
    "clientTrainLossHistory = np.asarray(clientTrainLossHistory)\n",
    "clientTrainAccHistory = np.asarray(clientTrainAccHistory)\n",
    "clientTestLossHistory = np.asarray(clientTestLossHistory)\n",
    "clientTestAccHistory = np.asarray(clientTestAccHistory)\n",
    "\n",
    "\n",
    "if(algorithm != 'FEDPER'):\n",
    "    serverTrainLossHistory = np.asarray(serverTrainLossHistory)\n",
    "    serverTrainAccHistory = np.asarray(serverTrainAccHistory)\n",
    "    serverTestLossHistory = np.asarray(serverTestLossHistory)\n",
    "    serverTestAccHistory = np.asarray(serverTestAccHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the training statistics and results\n",
    "os.makedirs(filepath+'trainingStats', exist_ok=True)\n",
    "\n",
    "hkl.dump(trainLossHistory,filepath + \"trainingStats/trainLossHistory.hkl\" )\n",
    "hkl.dump(trainAccHistory,filepath + \"trainingStats/trainAccHistory.hkl\" )\n",
    "hkl.dump(stdTrainLossHistory,filepath + \"trainingStats/stdTrainLossHistory.hkl\" )\n",
    "hkl.dump(stdTrainAccHistory,filepath + \"trainingStats/stdTrainAccHistory.hkl\" )\n",
    "\n",
    "hkl.dump(testLossHistory,filepath + \"trainingStats/testLossHistory.hkl\" )\n",
    "hkl.dump(testAccHistory,filepath + \"trainingStats/testAccHistory.hkl\" )\n",
    "hkl.dump(stdTestLossHistory,filepath + \"trainingStats/stdTestLossHistory.hkl\" )\n",
    "hkl.dump(stdTestAccHistory,filepath + \"trainingStats/stdTestAccHistory.hkl\" )\n",
    "    \n",
    "if(euclid):\n",
    "    hkl.dump(meanHistoryDist.tolist(),filepath + \"trainingStats/meanHistoryDist.hkl\" )\n",
    "    hkl.dump(stdHistoryDist.tolist(),filepath + \"trainingStats/stdHistoryDist.hkl\" )\n",
    "    hkl.dump(meanRoundLayerHistory,filepath + \"trainingStats/meanRoundLayerHistory.hkl\" )\n",
    "    hkl.dump(stdRoundLayerHistory,filepath + \"trainingStats/stdRoundLayerHistory.hkl\" )\n",
    "    hkl.dump(meanRoundGeneralLayerHistory,filepath + \"trainingStats/meanRoundGeneralLayerHistory.hkl\" )\n",
    "    hkl.dump(stdRoundGeneralLayerHistory,filepath + \"trainingStats/stdRoundGeneralLayerHistory.hkl\" )\n",
    "    \n",
    "if(ClientAllTest == True):\n",
    "    hkl.dump(clientStdTrainLossHistory,filepath + \"trainingStats/clientStdTrainLossHistory.hkl\" )\n",
    "    hkl.dump(clientStdTrainAccHistory,filepath + \"trainingStats/clientStdTrainAccHistory.hkl\" )\n",
    "    hkl.dump(clientStdTestLossHistory,filepath + \"trainingStats/clientStdTestLossHistory.hkl\" )\n",
    "    hkl.dump(clientStdTestAccHistory,filepath + \"trainingStats/clientStdTestAccHistory.hkl\" )\n",
    "\n",
    "    hkl.dump(clientTrainLossHistory,filepath + \"trainingStats/clientTrainLossHistory.hkl\" )\n",
    "    hkl.dump(clientTrainAccHistory,filepath + \"trainingStats/clientTrainAccHistory.hkl\" )\n",
    "    hkl.dump(clientTestLossHistory,filepath + \"trainingStats/clientTestLossHistory.hkl\" )\n",
    "    hkl.dump(clientTestAccHistory,filepath + \"trainingStats/clientTestAccHistory.hkl\" )\n",
    "\n",
    "if(algorithm != 'FEDPER'):\n",
    "    hkl.dump(serverTrainLossHistory,filepath + \"trainingStats/serverTrainLossHistory.hkl\" )\n",
    "    hkl.dump(serverTrainAccHistory,filepath + \"trainingStats/serverTrainAccHistory.hkl\" )\n",
    "    hkl.dump(serverTestLossHistory,filepath + \"trainingStats/serverTestLossHistory.hkl\" )\n",
    "    hkl.dump(serverTestAccHistory,filepath + \"trainingStats/serverTestAccHistory.hkl\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate line chart function\n",
    "def saveGraph(title = \"\",accuracyOrLoss = \"Accuracy\",asyTest = False,legendLoc = 'lower right'):\n",
    "    if(asyTest):\n",
    "        for stage in range(len(roundEnd)):\n",
    "            plt.axvline(roundEnd[stage], 0, 1,color =\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(accuracyOrLoss)\n",
    "    plt.xlabel('Communication Round')\n",
    "    plt.legend(loc=legendLoc)\n",
    "    plt.savefig(filepath+title.replace(\" \", \"\")+'.png', dpi=100)\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "epoch_range = range(1, communicationRound+1)\n",
    "if(seperateGraph):\n",
    "    if(algorithm != \"FEDPER\"):\n",
    "        plt.plot(epoch_range, serverTrainAccHistory, label = 'Server Train')\n",
    "        plt.plot(epoch_range, serverTestAccHistory, label= 'Server Test')\n",
    "        plt.plot(epoch_range, serverTrainAccHistory,markevery=[np.argmax(serverTrainAccHistory)], ls=\"\", marker=\"o\",color=\"blue\")\n",
    "        plt.plot(epoch_range, serverTestAccHistory,markevery=[np.argmax(serverTestAccHistory)], ls=\"\", marker=\"o\",color=\"orange\")\n",
    "        saveGraph(\"Server accuracy\",\"Accuracy\",asyTest = asyncTest)\n",
    "        \n",
    "    plt.errorbar(epoch_range, trainAccHistory, yerr=stdTrainAccHistory, label='Client Own Train',alpha=0.6)\n",
    "    plt.errorbar(epoch_range, testAccHistory, yerr=stdTestAccHistory, label='Client Own Test',alpha=0.6)\n",
    "    plt.plot(epoch_range, trainAccHistory,markevery=[np.argmax(trainAccHistory)], ls=\"\", marker=\"o\",color=\"green\")\n",
    "    plt.plot(epoch_range, testAccHistory,markevery=[np.argmax(testAccHistory)], ls=\"\", marker=\"o\",color=\"red\")  \n",
    "    saveGraph(\"Client own accuracy\",\"Accuracy\",asyTest = asyncTest)\n",
    "\n",
    "\n",
    "    if(ClientAllTest == True):\n",
    "        plt.errorbar(epoch_range, clientTrainAccHistory, yerr=clientStdTrainAccHistory, label='Client All Train',alpha=0.6)\n",
    "        plt.errorbar(epoch_range, clientTestAccHistory, yerr=clientStdTestAccHistory, label='Client All Test',alpha=0.6)\n",
    "        plt.plot(epoch_range, clientTrainAccHistory,markevery=[np.argmax(clientTrainAccHistory)], ls=\"\", marker=\"o\",color=\"purple\")\n",
    "        plt.plot(epoch_range, clientTestAccHistory,markevery=[np.argmax(clientTestAccHistory)], ls=\"\", marker=\"o\",color=\"brown\")  \n",
    "        saveGraph(\"Client all accuracy\",\"Accuracy\",asyTest = asyncTest)\n",
    "\n",
    "    if(algorithm != \"FEDPER\"):\n",
    "        plt.plot(epoch_range, serverTrainLossHistory, label = 'Server Train')\n",
    "        plt.plot(epoch_range, serverTestLossHistory, label= 'Server Test')\n",
    "        plt.plot(epoch_range, serverTrainLossHistory,markevery=[np.argmax(serverTrainLossHistory)], ls=\"\", marker=\"o\",color=\"blue\")\n",
    "        plt.plot(epoch_range, serverTestLossHistory,markevery=[np.argmax(serverTestLossHistory)], ls=\"\", marker=\"o\",color=\"orange\") \n",
    "        saveGraph(\"Server loss\",\"Loss\",asyTest = asyncTest,legendLoc = 'upper right')\n",
    "\n",
    "\n",
    "    plt.errorbar(epoch_range, trainLossHistory, yerr=stdTrainLossHistory, label='Client Own Train',alpha=0.6)\n",
    "    plt.errorbar(epoch_range, testLossHistory, yerr=stdTestLossHistory, label='Client Own Test',alpha=0.6)\n",
    "    plt.plot(epoch_range, trainLossHistory,markevery=[np.argmax(trainLossHistory)], ls=\"\", marker=\"o\",color=\"green\")\n",
    "    plt.plot(epoch_range, testLossHistory,markevery=[np.argmax(testLossHistory)], ls=\"\", marker=\"o\",color=\"red\") \n",
    "    \n",
    "    saveGraph(\"Client own loss\",\"Loss\",asyTest = asyncTest,legendLoc = 'upper right')\n",
    "\n",
    "    if(ClientAllTest == True):\n",
    "        plt.errorbar(epoch_range, clientTrainLossHistory, yerr=clientStdTrainLossHistory, label='Client All Train',alpha=0.6)\n",
    "        plt.errorbar(epoch_range, clientTestLossHistory, yerr=clientStdTestLossHistory, label='Client All Test',alpha=0.6)\n",
    "        plt.plot(epoch_range, clientTrainLossHistory,markevery=[np.argmax(clientTrainLossHistory)], ls=\"\", marker=\"o\",color=\"purple\")\n",
    "        plt.plot(epoch_range, clientTestLossHistory,markevery=[np.argmax(clientTestLossHistory)], ls=\"\", marker=\"o\",color=\"brown\")  \n",
    "        saveGraph(\"Client all loss\",\"Loss\",asyTest = asyncTest,legendLoc = 'upper right')\n",
    "else:\n",
    "    if(algorithm != \"FEDPER\"):\n",
    "        plt.plot(epoch_range, serverTrainAccHistory, label = 'Server Train')\n",
    "        plt.plot(epoch_range, serverTestAccHistory, label= 'Server Test')\n",
    "        plt.plot(epoch_range, serverTrainAccHistory,markevery=[np.argmax(serverTrainAccHistory)], ls=\"\", marker=\"o\",color=\"blue\")\n",
    "        plt.plot(epoch_range, serverTestAccHistory,markevery=[np.argmax(serverTestAccHistory)], ls=\"\", marker=\"o\",color=\"orange\") \n",
    "\n",
    "    plt.errorbar(epoch_range, trainAccHistory, yerr=stdTrainAccHistory, label='Client Own Train',alpha=0.6, color= \"green\")\n",
    "    plt.errorbar(epoch_range, testAccHistory, yerr=stdTestAccHistory, label='Client Own Test',alpha=0.6, color='red')\n",
    "\n",
    "    plt.plot(epoch_range, trainAccHistory,markevery=[np.argmax(trainAccHistory)], ls=\"\", marker=\"o\",color=\"green\")\n",
    "    plt.plot(epoch_range, testAccHistory,markevery=[np.argmax(testAccHistory)], ls=\"\", marker=\"o\",color=\"red\")  \n",
    "    \n",
    "    if(ClientAllTest == True):\n",
    "        plt.errorbar(epoch_range, clientTrainAccHistory, yerr=clientStdTrainAccHistory, label='Client All Train',alpha=0.6, color=\"purple\")\n",
    "        plt.errorbar(epoch_range, clientTestAccHistory, yerr=clientStdTestAccHistory, label='Client All Test',alpha=0.6, color=\"brown\")\n",
    "        plt.plot(epoch_range, clientTrainAccHistory,markevery=[np.argmax(clientTrainAccHistory)], ls=\"\", marker=\"o\",color=\"purple\")\n",
    "        plt.plot(epoch_range, clientTestAccHistory,markevery=[np.argmax(clientTestAccHistory)], ls=\"\", marker=\"o\",color=\"brown\")  \n",
    "\n",
    "        \n",
    "    if(asyncTest):\n",
    "        for stage in range(len(roundEnd)):\n",
    "            plt.axvline(roundEnd[stage], 0, 1,color =\"blue\")\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Communication Round')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig('LearningAccuracy.png', dpi=100)\n",
    "    plt.clf()\n",
    "\n",
    "    if(algorithm != \"FEDPER\"):\n",
    "        plt.plot(epoch_range, serverTrainLossHistory, label = 'Server Train')\n",
    "        plt.plot(epoch_range, serverTestLossHistory, label= 'Server Test')\n",
    "        plt.plot(epoch_range, serverTrainLossHistory,markevery=[np.argmin(serverTrainLossHistory)], ls=\"\", marker=\"o\",color=\"blue\")\n",
    "        plt.plot(epoch_range, serverTestLossHistory,markevery=[np.argmin(serverTestLossHistory)], ls=\"\", marker=\"o\",color=\"orange\") \n",
    "\n",
    "    plt.errorbar(epoch_range, trainLossHistory, yerr=stdTrainLossHistory, label='Client Own Train',alpha=0.6, color='green')\n",
    "    plt.errorbar(epoch_range, testLossHistory, yerr=stdTestLossHistory, label='Client Own Test',alpha=0.6, color='red')\n",
    "    plt.plot(epoch_range, trainLossHistory,markevery=[np.argmin(trainLossHistory)], ls=\"\", marker=\"o\",color=\"green\")\n",
    "    plt.plot(epoch_range, testLossHistory,markevery=[np.argmin(testLossHistory)], ls=\"\", marker=\"o\",color=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "    if(ClientAllTest == True):\n",
    "        plt.errorbar(epoch_range, clientTrainLossHistory, yerr=clientStdTrainLossHistory, label='Client All Train',alpha=0.6,color=\"purple\")\n",
    "        plt.errorbar(epoch_range, clientTestLossHistory, yerr=clientStdTestLossHistory, label='Client All Test',alpha=0.6,color=\"brown\")\n",
    "        plt.plot(epoch_range, clientTrainLossHistory,markevery=[np.argmin(clientTrainLossHistory)], ls=\"\", marker=\"o\",color=\"purple\")\n",
    "        plt.plot(epoch_range, clientTestLossHistory,markevery=[np.argmin(clientTestLossHistory)], ls=\"\", marker=\"o\",color=\"brown\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if(asyncTest):\n",
    "        for stage in range(len(roundEnd)):\n",
    "            plt.axvline(roundEnd[stage], 0, 1,color =\"blue\")\n",
    "\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Communication Round')\n",
    "    plt.legend(loc= 'upper right')\n",
    "    plt.savefig('LearningLoss.png', dpi=100)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohenD effect size normalize function\n",
    "def cohenDNormalize(mean1,mean2,std1,std2):\n",
    "    numerator = (mean1 - mean2)\n",
    "    denominater = np.sqrt(((std1**2) + (std2 **2)/2))\n",
    "    cohenDs = numerator / denominater \n",
    "    meanNormalized = mean1 * cohenDs \n",
    "    stdNormalized = std1 * cohenDs\n",
    "    return meanNormalized,stdNormalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating charts and graphs for dissimilarity mesasurements\n",
    "if(euclid):\n",
    "    roundEndIndex = 0\n",
    "    for stage in range(len(roundEnd)):\n",
    "        plt.axvline(roundEnd[stage], 0, 1,color =\"blue\")\n",
    "    for i in range(clientCount):\n",
    "        if(asyncTest):\n",
    "            for client in range(clientCount):\n",
    "                maskedIndex = []\n",
    "                for comRound in range(communicationRound):\n",
    "                    if(clientEuclidDistMean[client][comRound] == 0):\n",
    "                        maskedIndex.append(1)\n",
    "                    else:\n",
    "                        maskedIndex.append(0)\n",
    "                meanMask = np.ma.masked_array(clientEuclidDistMean[client], mask=maskedIndex)\n",
    "                stdMask = np.ma.masked_array(clientEuclidDistStd[client], mask=maskedIndex)\n",
    "                plt.errorbar(epoch_range, meanMask, yerr=stdMask, label='Client '+str(i+1),alpha=0.6)\n",
    "        else:\n",
    "            plt.errorbar(epoch_range, meanHistoryDist[i], yerr=stdHistoryDist[i], label='Client '+str(i+1))\n",
    "        \n",
    "    plt.title('Distance between client & server model')\n",
    "    plt.ylabel('Euclidiance Distance')\n",
    "    plt.xlabel('Communication Round')\n",
    "    plt.savefig(filepath+'allClientEuclid.png', dpi=100)\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "    if(algorithm != \"FEDPER\"):\n",
    "        for i in range(len(layerType)):\n",
    "#             hardcoded\n",
    "            if(i != 1):\n",
    "                meanRoundLayerHistory[i],stdRoundLayerHistory[i] = cohenDNormalize(meanRoundLayerHistory[i],meanRoundLayerHistory[1],stdRoundLayerHistory[i],stdRoundLayerHistory[1])\n",
    "            plt.errorbar(epoch_range, meanRoundLayerHistory[i], yerr=stdRoundLayerHistory[i], label='Layer '+str(i+1),alpha=0.6) \n",
    "    else:\n",
    "        plt.errorbar(epoch_range, meanRoundLayerHistory[0], yerr=stdRoundLayerHistory[0], label='Layer '+str(0+1),alpha=0.6) \n",
    "    if(asyncTest):\n",
    "        for stage in range(len(roundEnd)):\n",
    "            plt.axvline(roundEnd[stage], 0, 1,color =\"blue\")\n",
    "    plt.title('Layer distance between client & server model')\n",
    "    plt.ylabel('Euclidiance Distance')\n",
    "    plt.xlabel('Communication Round')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(filepath+'LayerClientEuclid.png', dpi=100)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding number function \n",
    "def roundNumber(toRoundNb):\n",
    "    return round(np.mean(toRoundNb), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating personalized accuracy\n",
    "indiAccTest = []\n",
    "indiWeightedTest = []\n",
    "indiMicroTest = []\n",
    "indiMacroTest = []\n",
    "os.makedirs(filepath+'models/' , exist_ok=True)\n",
    "for i in range(len(best_local_nets)):\n",
    "    best_local_nets[i].compile(optimizer=SGD(learning_rate=learningRate),loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    results = best_local_nets[i].evaluate(clientDataTest[i], clientLabelTest[i])\n",
    "    y_pred = best_local_nets[i].predict_classes(clientDataTest[i]) \n",
    "    y_test = clientLabelTest[i]\n",
    "    \n",
    "    _weightVal_f1 = f1_score(y_test, y_pred,average='weighted' )\n",
    "    _microVal_f1 = f1_score(y_test, y_pred,average='micro' )\n",
    "    _macroVal_f1 = f1_score(y_test, y_pred,average='macro' )\n",
    "    indiAccTest.append(results[1])\n",
    "    indiWeightedTest.append(_weightVal_f1)\n",
    "    indiMicroTest.append(_microVal_f1)\n",
    "    indiMacroTest.append(_macroVal_f1)\n",
    "    if(savedClientModel == 1):\n",
    "        best_local_nets[i].save(filepath+'models/clientModel'+str(i+1)+'.h5')\n",
    "\n",
    "    \n",
    "modelStatistics = {\n",
    "    \"Results on individual client models on their own tests\" : '',\n",
    "    \"BestModelRound:\": bestModelRound,\n",
    "    \"accuracy:\" : roundNumber(np.mean(indiAccTest)),\n",
    "    \"weighted f1:\" : roundNumber(np.mean(indiWeightedTest)),\n",
    "    \"micro f1:\": roundNumber(np.mean(indiMicroTest)),\n",
    "    \"macro f1:\": roundNumber(np.mean(indiMacroTest)),\n",
    "}    \n",
    "with open(filepath +'indivualClientsMeasure.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(modelStatistics.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating generalized accuracy\n",
    "indiAccTest = []\n",
    "indiWeightedTest = []\n",
    "indiMicroTest = []\n",
    "indiMacroTest = []\n",
    "\n",
    "for i in range(len(best_local_nets)):\n",
    "    results = best_local_nets[i].evaluate(centralTestData, centralTestLabel)\n",
    "    y_pred = best_local_nets[i].predict_classes(centralTestData) \n",
    "    y_test = centralTestLabel\n",
    "    \n",
    "    _weightVal_f1 = f1_score(y_test, y_pred,average='weighted' )\n",
    "    _microVal_f1 = f1_score(y_test, y_pred,average='micro' )\n",
    "    _macroVal_f1 = f1_score(y_test, y_pred,average='macro' )\n",
    "    indiAccTest.append(results[1])\n",
    "    indiWeightedTest.append(_weightVal_f1)\n",
    "    indiMicroTest.append(_microVal_f1)\n",
    "    indiMacroTest.append(_macroVal_f1)\n",
    "\n",
    "modelStatistics = {\n",
    "\"Results on individual client models on ALL testsets\" : '',\n",
    "\"Client Best Model Round:\": bestModelRound,\n",
    "\"Client Accuracy:\" : roundNumber(np.mean(indiAccTest)),\n",
    "\"Client weighted f1:\" : roundNumber(np.mean(indiWeightedTest)),\n",
    "\"Client micro f1:\": roundNumber(np.mean(indiMicroTest)),\n",
    "\"Client macro f1:\": roundNumber(np.mean(indiMacroTest)),\n",
    "}    \n",
    "with open(filepath +'AllClientsMeasure.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(modelStatistics.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Global accuracy\n",
    "if(algorithm != \"FEDPER\"):\n",
    "    results = bestServerModel.evaluate(centralTestData, centralTestLabel)\n",
    "    y_pred = bestServerModel.predict_classes(centralTestData)\n",
    "    y_test = centralTestLabel\n",
    "    weightVal_f1 = f1_score(y_test, y_pred,average='weighted' )\n",
    "    microVal_f1 = f1_score(y_test, y_pred,average='micro')\n",
    "    macroVal_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "    \n",
    "    bestServerModel.save(filepath+'models/serverModel.h5')\n",
    "    modelStatistics = {\n",
    "    \"Results on server model on ALL testsets\" : '',\n",
    "    \"Server Best Model Round\": serverbestModelRound,\n",
    "    \"Server Accuracy:\" : roundNumber(serverCurrentAccuracy),\n",
    "    \"Server weighted f1:\" : roundNumber(weightVal_f1),\n",
    "    \"Server micro f1:\": roundNumber(microVal_f1),\n",
    "    \"Server macro f1:\": roundNumber(macroVal_f1),\n",
    "    }    \n",
    "    with open(filepath +'ServerMeasure.csv','w') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerows(modelStatistics.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the training time per round\n",
    "modelStatistics = {\n",
    "    \"Training Time:\": endTime,    \n",
    "}\n",
    "with open(filepath +'traingTime.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(modelStatistics.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
